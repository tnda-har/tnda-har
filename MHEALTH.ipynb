{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gtda.time_series import  SlidingWindow\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.diagrams import BettiCurve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import  BernoulliNB, MultinomialNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data_list = []\n",
    "    for i in os.listdir(path):\n",
    "        path_name = path + i\n",
    "        data = pd.read_csv(path_name, header=None, sep='\\t')\n",
    "        data_list.append(data)\n",
    "    dataset = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    dataset.columns = ['C_A1', 'C_A2', 'C_A3', 'E_1', 'E_2', 'LA_A1', 'LA_A2', 'LA_A3',\n",
    "                       'LA_G1', 'LA_G2', 'LA_3G', 'LA_M1', 'LA_M2','LA_M3','RL_arm_A1',\n",
    "                       'RL_arm_A2', 'RL_arm_A3', 'RL_arm_G1', 'RL_arm_G2', 'RL_arm_G3',\n",
    "                       'RL_arm_M1', 'RL_arm_M2', 'RL_arm_M3', 'class']\n",
    "\n",
    "    dataset.drop(index=list(dataset[dataset['class'] == 0].index), inplace=True)\n",
    "    X = dataset.drop(columns=['class', 'E_1', 'E_2'])\n",
    "    y = dataset['class']\n",
    "    y = pd.DataFrame(y)\n",
    "    y[y <= 3] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocesssing(data, label, size, stride):\n",
    "    Scaler = MinMaxScaler()\n",
    "    data_ = Scaler.fit_transform(data)\n",
    "    SW = SlidingWindow(size=size, stride=stride)\n",
    "    X, y = SW.fit_transform_resample(data_, label)\n",
    "    return  X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_feature(data, time_delay, dimension):\n",
    "    featuress = []\n",
    "    for i in tqdm(range(data.shape[2])):\n",
    "        data_ = data[:, :, i]\n",
    "        TE = TakensEmbedding(time_delay=time_delay, dimension=dimension)\n",
    "        Taken = TE.fit_transform(data_)\n",
    "        VR = VietorisRipsPersistence(\n",
    "            metric=\"euclidean\",\n",
    "            homology_dimensions=[0, 1],\n",
    "            n_jobs=6,\n",
    "            collapse_edges=True)\n",
    "        VRs = VR.fit_transform(Taken)\n",
    "        BE = BettiCurve()\n",
    "        feature = BE.fit_transform(VRs)\n",
    "        feature = feature.sum(axis=1)\n",
    "        featuress.append(feature)\n",
    "        time.sleep(1)\n",
    "    featuress = np.concatenate(featuress, axis=1)\n",
    "    return featuress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_RFC(feature, label,n_splits):\n",
    "    X, X_valid, y, y_valid = train_test_split(feature, label, test_size=0.3, random_state=42)\n",
    "    RFC = RandomForestClassifier()\n",
    "    RFC.fit(X, y)\n",
    "    acc_score = RFC.score(X_valid, y_valid)\n",
    "    print(acc_score)\n",
    "    y_pred = RFC.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, digits=4))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(RFC, feature, label, cv=cv)\n",
    "    print(score)\n",
    "    print(score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_NB(feature, label,n_splits):\n",
    "    X, X_valid, y, y_valid = train_test_split(feature, label, test_size=0.3)\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(X, y)\n",
    "    acc_score = NB.score(X_valid, y_valid)\n",
    "    print(acc_score)\n",
    "    y_pred = NB.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, digits=4))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(NB, feature, label, cv=cv)\n",
    "    print(score)\n",
    "    print( score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_SVM(feature, label,n_splits):\n",
    "    X, X_valid, y, y_valid = train_test_split(feature, label, test_size=0.3)\n",
    "    SVM = svm.SVC(kernel='rbf')\n",
    "    SVM.fit(X, y)\n",
    "    print(SVM.score(X_valid, y_valid))\n",
    "    y_pred = SVM.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, digits=4))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(SVM, feature, label, cv=cv)\n",
    "    print(score)\n",
    "    print( score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_XGB(feature, label,n_splits):\n",
    "    X, X_valid, y, y_valid = train_test_split(feature, label, test_size=0.3)\n",
    "    num_round = 150\n",
    "    bst = XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=num_round, objective='binary:logistic')\n",
    "    bst.fit(X, y)\n",
    "    y_pred = bst.predict(X_valid)\n",
    "    print(classification_report(y_valid, y_pred, digits=4))\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    score = cross_val_score(bst, feature, label, cv=cv)\n",
    "    print(score)\n",
    "    print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='./MHEALTHDATASET/'\n",
    "data,label = load_data(path)\n",
    "data_processed, label_processed = data_preprocesssing(data, label, 128, 64)\n",
    "feature = extract_feature(data_processed, 5, 10)\n",
    "model_RFC(feature, label_processed, 5)\n",
    "model_NB(feature, label_processed, 5)\n",
    "model_SVM(feature, label_processed, 5)\n",
    "model_XGB(feature, label_processed, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
